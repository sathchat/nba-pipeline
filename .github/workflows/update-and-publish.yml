name: Update NBA dataset and publish to Kaggle

on:
  schedule:
    - cron: "0 12 * * *"    # daily 12:00 UTC (~08:00 America/New_York)
  workflow_dispatch:
    inputs:
      smoketest:
        description: "Run a known in-season window and print counts"
        required: false
        default: "false"
      start:
        description: "Optional START_DATE (YYYY-MM-DD) for manual run"
        required: false
      end:
        description: "Optional END_DATE (YYYY-MM-DD) for manual run"
        required: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 35
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          set -euxo pipefail
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install kaggle

      - name: Seed empty CSVs if missing (headers only)
        run: |
          set -euxo pipefail
          python - <<'PY'
          import os, csv
          os.makedirs('export', exist_ok=True)
          def ensure(path, cols):
              if not os.path.exists(path):
                  with open(path,'w',newline='',encoding='utf-8') as f:
                      csv.writer(f).writerow(cols)
          games_cols = ["gameId","gameCode","gameDateEt","gameStatusText","period","gameClock","arenaName",
                        "homeTeamId","homeTeamTricode","homeScore","awayTeamId","awayTeamTricode","awayScore"]
          players_cols = ["gameId","playerId","teamId","teamTricode","firstName","familyName","jerseyNum","position",
                          "minutes","points","reboundsTotal","assists","steals","blocks","turnovers",
                          "fieldGoalsMade","fieldGoalsAttempted","threePointersMade","threePointersAttempted",
                          "freeThrowsMade","freeThrowsAttempted","plusMinus","didNotPlay","notPlayingReason"]
          team_cols = ["gameId","teamId","teamTricode","teamCity","teamName","opponentTeamId","home","win",
                       "points","reboundsTotal","assists","steals","blocks","turnovers",
                       "fieldGoalsMade","fieldGoalsAttempted","threePointersMade","threePointersAttempted",
                       "freeThrowsMade","freeThrowsAttempted"]
          ensure('export/games.csv', games_cols)
          ensure('export/player_stats.csv', players_cols)
          ensure('export/team_stats.csv', team_cols)
          PY

      # ---------- ONE-TIME: run this from the UI with smoketest=true ----------
      - name: Smoketest (known in-season window)
        if: ${{ github.event_name == 'workflow_dispatch' && inputs.smoketest == 'true' }}
        env:
          START_DATE: ${{ inputs.start != '' && inputs.start || '2016-01-15' }}
          END_DATE:   ${{ inputs.end   != '' && inputs.end   || '2016-01-16' }}
        run: |
          set -euxo pipefail
          python src/ingest.py
          echo "Line counts (should be >1 each):"
          wc -l export/games.csv export/team_stats.csv export/player_stats.csv || true
          head -n 5 export/games.csv || true
          head -n 5 export/team_stats.csv || true
          head -n 5 export/player_stats.csv || true

      # ---------- normal ingest (yesterday+today) or manual window ----------
      - name: Ingest latest NBA data
        if: ${{ ! (github.event_name == 'workflow_dispatch' && inputs.smoketest == 'true') }}
        env:
          START_DATE: ${{ inputs.start }}
          END_DATE:   ${{ inputs.end }}
        run: |
          set -euxo pipefail
          python src/ingest.py
          echo "Heads:"
          head -n 5 export/games.csv || true
          head -n 5 export/team_stats.csv || true
          head -n 5 export/player_stats.csv || true

      - name: Check data counts (decide whether to publish)
        id: check
        run: |
          set -euxo pipefail
          gc=$( [ -f export/games.csv ] && wc -l < export/games.csv || echo 0 )
          tc=$( [ -f export/team_stats.csv ] && wc -l < export/team_stats.csv || echo 0 )
          pc=$( [ -f export/player_stats.csv ] && wc -l < export/player_stats.csv || echo 0 )
          echo "games=$gc team=$tc players=$pc"
          if [ "$gc" -gt 1 ] && [ "$tc" -gt 1 ] && [ "$pc" -gt 1 ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - name: Configure Kaggle CLI
        if: ${{ steps.check.outputs.has_data == 'true' }}
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          set -euxo pipefail
          mkdir -p ~/.kaggle
          printf '{"username":"%s","key":"%s"}\n' "$KAGGLE_USERNAME" "$KAGGLE_KEY" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
          kaggle --version
          echo "Using Kaggle owner: $KAGGLE_USERNAME"
          echo "Searching for dataset by owner+slug:"
          kaggle datasets list -o "$KAGGLE_USERNAME" -s "nba-daily-updates" -p 1 || true

      - name: Patch dataset owner in metadata to your Kaggle handle
        if: ${{ steps.check.outputs.has_data == 'true' }}
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        run: |
          set -euxo pipefail
          sed -i -E "s/\"id\": \"[^\"]*\\/nba-daily-updates\"/\"id\": \"${KAGGLE_USERNAME//\//\\/}\\/nba-daily-updates\"/g" dataset-metadata.json
          cat dataset-metadata.json

      - name: Create or version Kaggle dataset (only when data exists)
        if: ${{ steps.check.outputs.has_data == 'true' }}
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
        run: |
          set -euxo pipefail
          DS="${KAGGLE_USERNAME}/nba-daily-updates"
          # Only package files referenced in dataset-metadata.json; .kaggleignore filters others
          if kaggle datasets status "$DS" > /dev/null 2>&1; then
            kaggle datasets version -p . -m "Daily update" -r zip --dir-mode zip
          else
            # Use --public if you want it visible without logging in
            kaggle datasets create -p . --public
          fi
          echo "Dataset URL: https://www.kaggle.com/datasets/$KAGGLE_USERNAME/nba-daily-updates"

      - name: Explain skip
        if: ${{ steps.check.outputs.has_data != 'true' }}
        run: echo "Skip publish: no data collected (off-season window, API outage, or wrong dates)."
